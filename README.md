# Deep Joint Source-Channel Coding for Wireless Image Transmission

This repository contains a complete implementation and reproduction of the experiments from the seminal paper: ["Deep Joint Source-Channel Coding for Wireless Image Transmission"]. The project is structured to be a faithful and verifiable replication of the paper's core results, demonstrating the superiority of the Deep JSCC approach over traditional separation-based methods like `JPEG` and `JPEG2000`.

This implementation was developed as a personal research project to deeply understand the principles of deep learning-based communication systems. It is intended to be a clean, well-documented, and easily reproducible codebase.

## Key Features

* **Faithful Reproduction:** The code successfully reproduces the main performance curves for the AWGN channel presented in the original paper.
* **Multiple Datasets:** Supports both the **CIFAR-10** and **Kodak** image datasets for training and evaluation.
* **Standard Benchmarks:** Includes scripts to generate performance data for **JPEG** and **JPEG2000** codecs, providing a clear baseline for comparison.
* **Modular Codebase:** The project is organized into logical modules for data loading, model definition, training, evaluation, and visualization, following best practices in research software engineering.
* **End-to-End Workflow:** Provides a complete, three-stage pipeline to move from a raw dataset to a final, publication-quality performance graph.

## Final Results

The following graph, generated by the `plot_result.py` script, demonstrates the final output of this project. It plots the Peak Signal-to-Noise Ratio (PSNR) against the channel Signal-to-Noise Ratio (SNR) for the CIFAR-10 dataset, clearly showing that the Deep JSCC model (blue line) outperforms the traditional JPEG and JPEG2000 methods across a range of channel qualities.

*This is a placeholder for your final generated image. You should replace `benchmark_vs_deep_jscc.png` with the actual graph generated by your code.*


<img width="296" alt="image" src="https://github.com/user-attachments/assets/b5fbca84-b57c-4b69-b2d6-ad1344788e7d" />


## Project Structure

The repository is organized as follows, separating concerns for clarity and maintainability:

| File | Description |
| :--- | :--- |
| `README.md` | You are here! |
| **Data & Configuration** | |
| `data_load.py` | Handles loading and preprocessing for CIFAR-10 and Kodak datasets. |
| `config.py` | Contains global default configurations and hyperparameters. |
| `requirements.txt` | Lists all necessary Python dependencies for one-step installation. |
| **Core Model & Logic** | |
| `model.py` | Defines the `Autoencoder` neural network architecture for the Deep JSCC codec. |
| `train.py` | Contains the core training and validation loops. |
| `utils.py` | A utility module for common functions like PSNR/SSIM calculation, channel models, etc. |
| **Execution Scripts** | |
| `main.py` | The main entry point for training a new model with specified parameters (e.g., SNR). |
| `evaluate.py` | Loads a pre-trained model (`.pth` file) and evaluates its performance. |
| `benchmark.py` | Runs the benchmark tests against JPEG and JPEG2000 codecs. |
| **Plotting & Visualization** | |
| `plot_result.py` | Gathers all `.json` results (from benchmarks and model evaluations) and generates the final comparison plot. |
| `visualization.py` | Provides helper functions for plotting and image visualization. |

## Setup and Replication Workflow

Follow these steps to set up the environment and reproduce the results from scratch.

### 1. Prerequisites

* **Python 3.10+**
* **For Windows:** Microsoft C++ Build Tools (available from the [Visual Studio downloader](https://visualstudio.microsoft.com/visual-cpp-build-tools/)).
* **For macOS/Linux:** Standard build essentials (e.g., `build-essential` on Debian/Ubuntu, or `xcode-select --install` on macOS).
* **OpenJPEG:** The `opj_compress` command-line tool is required for the JPEG2000 benchmark. Please download it from the [official OpenJPEG releases](https://github.com/uclouvain/openjpeg/releases) and add the `bin` directory to your system's PATH.

### 2. Installation

First, clone the repository and navigate into the project directory.
```
git clone <your-repository-url>
cd <repository-name>
```
Next, it is highly recommended to create a Python virtual environment to isolate project dependencies.

#### Create the virtual environment
`python -m venv venv`

#### Activate the environment
##### On macOS/Linux:
`source venv/bin/activate`
##### On Windows (CMD):
`venv\Scripts\activate`

Finally, install all required libraries using the requirements.txt file.

`pip install -r requirements.txt`

### 3. Dataset Preparation

CIFAR-10: No action is needed. The dataset will be automatically downloaded the first time the training script is run.

Kodak:
Create a folder named kodak_dataset in the root of the project directory.

Download the 24 images from the official Kodak Lossless True Color Image Suite.

Place all 24 `.png` images into the `kodak_dataset` folder.

### 4. Running the Experiments

The full workflow consists of three main stages.

#### Stage 1: Generate Benchmark Data
Run the benchmark.py script for your desired dataset. This will generate the performance data for `JPEG` and `JPEG2000`, saving the results as `.json` files in the `./results` directory.

#### Run on Kodak (fast)
`python benchmark.py --dataset kodak`

#### Or run on CIFAR-10 (can take several hours)
`python benchmark.py --dataset cifar10`


#### Stage 2: Train and Evaluate Deep JSCC Models
To generate each point on the performance curve, you must train and then evaluate a model for a specific SNR and compression ratio.

##### --- Example for a single data point on the CIFAR-10 curve ---

##### 1. Train the model for SNR=10dB
`python main.py --dataset cifar10 --snr_db 10 --compression_ratio 0.0833`

##### 2. Evaluate the newly trained model (check model path in the ./models folder)
`python evaluate.py --model_path ./models/deep_jscc_cifar10_snr10_awgn_kn0.0833.pth`

Repeat this process for all desired SNR values to trace the full performance curve.

#### Stage 3: Generate the Final Comparison Plot
Once all benchmark and model evaluation .json files are present in the ./results folder, run the plot_result.py script to generate the final `benchmark_vs_deep_jscc.png` graph.

`python plot_result.py --dataset cifar10`

This final image is the culmination of the project, providing a clear visual summary of the reproduced results.
